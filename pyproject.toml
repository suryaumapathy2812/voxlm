[project]
name = "voxlm"
version = "0.1.0"
description = "Modular Speech-to-Text: Any audio encoder + Any LLM with word-level timestamps"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    # Core ML
    "torch>=2.0.0",
    "torchaudio>=2.0.0",
    "transformers>=4.36.0",
    
    # LoRA fine-tuning
    "peft>=0.7.0",
    "accelerate>=0.25.0",
    
    # Audio processing
    "librosa>=0.10.0",
    "soundfile>=0.12.0",
    
    # Data handling
    "datasets>=2.15.0",
    "numpy>=1.24.0",
    
    # Configuration
    "pyyaml>=6.0.0",
    
    # Training utilities
    "wandb>=0.16.0",
    "tqdm>=4.66.0",
    
    # Evaluation
    "jiwer>=3.0.0",
    
    # Timestamp generation
    "openai-whisper>=20231117",
]

[project.optional-dependencies]
dev = [
    "jupyter>=1.0.0",
    "ipykernel>=6.0.0",
    "ipywidgets>=8.0.0",
    "matplotlib>=3.7.0",
    "pytest>=7.0.0",
    "ruff>=0.1.0",
]
whisperx = [
    "whisperx>=3.1.0",
]
8bit = [
    "bitsandbytes>=0.41.0",
]

[project.scripts]
voxlm-train = "scripts.train:main"
voxlm-inference = "scripts.inference:main"
voxlm-timestamps = "scripts.generate_timestamps:main"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["src"]

[dependency-groups]
dev = [
    "jupyter>=1.0.0",
    "ipykernel>=6.0.0",
    "pytest>=7.0.0",
    "ruff>=0.1.0",
]

[tool.uv]
python-preference = "only-managed"
